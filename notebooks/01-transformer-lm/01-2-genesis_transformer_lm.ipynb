{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Setup and Data Loading"
      ],
      "metadata": {
        "id": "NIJFGo4VECal"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfhztOnuBSIz",
        "outputId": "62971bd8-9228-4956-a9ef-dc728a90dda0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Characters in Genesis text: 4448806\n",
            "1:1 In the beginning God created the heaven and the earth.\r\n",
            "\r\n",
            "1:2 And the earth was without form, and void; and darkness was upon\r\n",
            "the face of the deep. And the Spirit of God moved upon the face of the\r\n",
            "waters.\r\n",
            "\r\n",
            "1:3 And God said, Let there be light: and there was light.\r\n",
            "\r\n",
            "1:4 And God saw the light, that it was good: and God divided the light\r\n",
            "from the darkness.\r\n",
            "\r\n",
            "1:5 And God called the light Day, and the darkness he called Night.\r\n",
            "And the evening and the morning were the first day.\r\n",
            "\r\n",
            "1:6 An\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "# Download King James Bible from Project Gutenberg\n",
        "url = \"https://www.gutenberg.org/cache/epub/10/pg10.txt\"\n",
        "response = requests.get(url)\n",
        "text = response.text\n",
        "\n",
        "# Extract only Genesis\n",
        "start = text.find(\"1:1 In the beginning God created the heaven and the earth.\")\n",
        "end = text.find(\"The Second Book of Moses:  Called Exodus\")\n",
        "genesis_text = text[start:end]\n",
        "\n",
        "print(\"Characters in Genesis text:\", len(genesis_text))\n",
        "print(genesis_text[:500])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Vocabulary"
      ],
      "metadata": {
        "id": "H0oxXMguEIJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(genesis_text)))\n",
        "vocab_size = len(chars)\n",
        "print(\"Vocabulary size:\", vocab_size)\n",
        "print(\"Characters:\", ''.join(chars))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NI5OJUapCLor",
        "outputId": "0c2d0044-f1ef-4043-a8a3-8a77162429f4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 85\n",
            "Characters: \n",
            "\r !$%()*,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz—‘’“”•™\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a mapping from characteres to integers (Chars Tokenization)"
      ],
      "metadata": {
        "id": "CWKE5LojEpYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "itos = {i: ch for i, ch in enumerate(chars)}\n"
      ],
      "metadata": {
        "id": "pGCcKRhjEtvq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Tokenization + Detokenization)"
      ],
      "metadata": {
        "id": "pUy8x3UFKfwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encode = lambda s: [stoi[c] for c in s]   # string → list of ints\n",
        "decode = lambda l: ''.join([itos[i] for i in l])  # list of ints → string\n",
        "\n",
        "print(stoi)\n",
        "print(itos)"
      ],
      "metadata": {
        "id": "gKd4ONUtKXM6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85ec58e8-56e7-49d3-c89c-6fc3b3a61f28"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'\\n': 0, '\\r': 1, ' ': 2, '!': 3, '$': 4, '%': 5, '(': 6, ')': 7, '*': 8, ',': 9, '-': 10, '.': 11, '/': 12, '0': 13, '1': 14, '2': 15, '3': 16, '4': 17, '5': 18, '6': 19, '7': 20, '8': 21, '9': 22, ':': 23, ';': 24, '?': 25, 'A': 26, 'B': 27, 'C': 28, 'D': 29, 'E': 30, 'F': 31, 'G': 32, 'H': 33, 'I': 34, 'J': 35, 'K': 36, 'L': 37, 'M': 38, 'N': 39, 'O': 40, 'P': 41, 'Q': 42, 'R': 43, 'S': 44, 'T': 45, 'U': 46, 'V': 47, 'W': 48, 'X': 49, 'Y': 50, 'Z': 51, 'a': 52, 'b': 53, 'c': 54, 'd': 55, 'e': 56, 'f': 57, 'g': 58, 'h': 59, 'i': 60, 'j': 61, 'k': 62, 'l': 63, 'm': 64, 'n': 65, 'o': 66, 'p': 67, 'q': 68, 'r': 69, 's': 70, 't': 71, 'u': 72, 'v': 73, 'w': 74, 'x': 75, 'y': 76, 'z': 77, '—': 78, '‘': 79, '’': 80, '“': 81, '”': 82, '•': 83, '™': 84}\n",
            "{0: '\\n', 1: '\\r', 2: ' ', 3: '!', 4: '$', 5: '%', 6: '(', 7: ')', 8: '*', 9: ',', 10: '-', 11: '.', 12: '/', 13: '0', 14: '1', 15: '2', 16: '3', 17: '4', 18: '5', 19: '6', 20: '7', 21: '8', 22: '9', 23: ':', 24: ';', 25: '?', 26: 'A', 27: 'B', 28: 'C', 29: 'D', 30: 'E', 31: 'F', 32: 'G', 33: 'H', 34: 'I', 35: 'J', 36: 'K', 37: 'L', 38: 'M', 39: 'N', 40: 'O', 41: 'P', 42: 'Q', 43: 'R', 44: 'S', 45: 'T', 46: 'U', 47: 'V', 48: 'W', 49: 'X', 50: 'Y', 51: 'Z', 52: 'a', 53: 'b', 54: 'c', 55: 'd', 56: 'e', 57: 'f', 58: 'g', 59: 'h', 60: 'i', 61: 'j', 62: 'k', 63: 'l', 64: 'm', 65: 'n', 66: 'o', 67: 'p', 68: 'q', 69: 'r', 70: 's', 71: 't', 72: 'u', 73: 'v', 74: 'w', 75: 'x', 76: 'y', 77: 'z', 78: '—', 79: '‘', 80: '’', 81: '“', 82: '”', 83: '•', 84: '™'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- encode(\"Hello\") → [id1, id2, id3, id4, id5]\n",
        "- decode([id1, id2, id3, id4, id5]) → \"Hello\""
      ],
      "metadata": {
        "id": "AaOGyCNuXQYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "print(encode(\"And God said, Let there be light.\"))\n",
        "print(decode(encode(\"And God said, Let there be light.\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUEVJP59Gy9y",
        "outputId": "014f2b0c-ddbc-4052-a0da-7d4bd84c49cc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[26, 65, 55, 2, 32, 66, 55, 2, 70, 52, 60, 55, 9, 2, 37, 56, 71, 2, 71, 59, 56, 69, 56, 2, 53, 56, 2, 63, 60, 58, 59, 71, 11]\n",
            "And God said, Let there be light.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train/Validation Split\n",
        "\n",
        "- Let's now split up the data into train and validation sets"
      ],
      "metadata": {
        "id": "XQR-Drm2e_pg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "data = torch.tensor(encode(genesis_text), dtype=torch.long)\n",
        "n = int(0.9 * len(data)) # 90% to training\n",
        "\n",
        "train_data = data[:n]\n",
        "val_data = data[n:] # 10% to validate\n",
        "len(train_data), len(val_data)\n",
        "\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oYKGFVkfGrH",
        "outputId": "d0433216-2c5c-4f51-c959-c36618e3768d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4448806]) torch.int64\n",
            "tensor([14, 23, 14,  2, 34, 65,  2, 71, 59, 56,  2, 53, 56, 58, 60, 65, 65, 60,\n",
            "        65, 58,  2, 32, 66, 55,  2, 54, 69, 56, 52, 71, 56, 55,  2, 71, 59, 56,\n",
            "         2, 59, 56, 52, 73, 56, 65,  2, 52, 65, 55,  2, 71, 59, 56,  2, 56, 52,\n",
            "        69, 71, 59, 11,  1,  0,  1,  0, 14, 23, 15,  2, 26, 65, 55,  2, 71, 59,\n",
            "        56,  2, 56, 52, 69, 71, 59,  2, 74, 52, 70,  2, 74, 60, 71, 59, 66, 72,\n",
            "        71,  2, 57, 66, 69, 64,  9,  2, 52, 65])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batching Function"
      ],
      "metadata": {
        "id": "mRZehBpLkr_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "batch_size = 4\n",
        "\n",
        "def get_batch(split):\n",
        "    data_split = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data_split) - block_size, (batch_size,)) # random training\n",
        "    x = torch.stack([data_split[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data_split[i+1:i+block_size+1] for i in ix])\n",
        "    return x, y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print(xb.shape, yb.shape)"
      ],
      "metadata": {
        "id": "GwFnnLwgkuFc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dfa611d-a4e3-460e-9741-f339fa318fb4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 8]) torch.Size([4, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demonstration to map input - target"
      ],
      "metadata": {
        "id": "509m79FjURrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for b in range(batch_size):\n",
        "    for t in range(block_size):\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b, t]\n",
        "        print(f\"when input (x) is {context.tolist()} the target (y) is: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02ekOqS0SMfe",
        "outputId": "0f0ef5ef-13a0-4dc5-959f-2f506af26cf1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input (x) is [58] the target (y): 69\n",
            "when input (x) is [58, 69] the target (y): 52\n",
            "when input (x) is [58, 69, 52] the target (y): 65\n",
            "when input (x) is [58, 69, 52, 65] the target (y): 52\n",
            "when input (x) is [58, 69, 52, 65, 52] the target (y): 71\n",
            "when input (x) is [58, 69, 52, 65, 52, 71] the target (y): 56\n",
            "when input (x) is [58, 69, 52, 65, 52, 71, 56] the target (y): 70\n",
            "when input (x) is [58, 69, 52, 65, 52, 71, 56, 70] the target (y): 24\n",
            "when input (x) is [52] the target (y): 65\n",
            "when input (x) is [52, 65] the target (y): 55\n",
            "when input (x) is [52, 65, 55] the target (y): 2\n",
            "when input (x) is [52, 65, 55, 2] the target (y): 55\n",
            "when input (x) is [52, 65, 55, 2, 55] the target (y): 74\n",
            "when input (x) is [52, 65, 55, 2, 55, 74] the target (y): 56\n",
            "when input (x) is [52, 65, 55, 2, 55, 74, 56] the target (y): 63\n",
            "when input (x) is [52, 65, 55, 2, 55, 74, 56, 63] the target (y): 71\n",
            "when input (x) is [52] the target (y): 74\n",
            "when input (x) is [52, 74] the target (y): 52\n",
            "when input (x) is [52, 74, 52] the target (y): 76\n",
            "when input (x) is [52, 74, 52, 76] the target (y): 9\n",
            "when input (x) is [52, 74, 52, 76, 9] the target (y): 2\n",
            "when input (x) is [52, 74, 52, 76, 9, 2] the target (y): 65\n",
            "when input (x) is [52, 74, 52, 76, 9, 2, 65] the target (y): 66\n",
            "when input (x) is [52, 74, 52, 76, 9, 2, 65, 66] the target (y): 69\n",
            "when input (x) is [65] the target (y): 55\n",
            "when input (x) is [65, 55] the target (y): 2\n",
            "when input (x) is [65, 55, 2] the target (y): 74\n",
            "when input (x) is [65, 55, 2, 74] the target (y): 60\n",
            "when input (x) is [65, 55, 2, 74, 60] the target (y): 63\n",
            "when input (x) is [65, 55, 2, 74, 60, 63] the target (y): 63\n",
            "when input (x) is [65, 55, 2, 74, 60, 63, 63] the target (y): 2\n",
            "when input (x) is [65, 55, 2, 74, 60, 63, 63, 2] the target (y): 65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    return x, y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print('----')\n",
        "\n",
        "for b in range(batch_size): # batch dimension\n",
        "    for t in range(block_size): # time dimension\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0M4lXK23cP6j",
        "outputId": "cc836cbe-611e-4b0a-9bd6-4a515504be56"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "torch.Size([4, 8])\n",
            "tensor([[63, 56, 71, 59, 11,  2, 32, 66],\n",
            "        [63, 63,  2, 71, 59, 56, 70, 56],\n",
            "        [70, 56, 63, 73, 56, 70,  1,  0],\n",
            "        [ 2, 26, 59, 60, 63, 72, 55,  2]])\n",
            "targets:\n",
            "torch.Size([4, 8])\n",
            "tensor([[56, 71, 59, 11,  2, 32, 66,  2],\n",
            "        [63,  2, 71, 59, 56, 70, 56,  2],\n",
            "        [56, 63, 73, 56, 70,  1,  0, 74],\n",
            "        [26, 59, 60, 63, 72, 55,  2, 74]])\n",
            "----\n",
            "when input is [63] the target: 56\n",
            "when input is [63, 56] the target: 71\n",
            "when input is [63, 56, 71] the target: 59\n",
            "when input is [63, 56, 71, 59] the target: 11\n",
            "when input is [63, 56, 71, 59, 11] the target: 2\n",
            "when input is [63, 56, 71, 59, 11, 2] the target: 32\n",
            "when input is [63, 56, 71, 59, 11, 2, 32] the target: 66\n",
            "when input is [63, 56, 71, 59, 11, 2, 32, 66] the target: 2\n",
            "when input is [63] the target: 63\n",
            "when input is [63, 63] the target: 2\n",
            "when input is [63, 63, 2] the target: 71\n",
            "when input is [63, 63, 2, 71] the target: 59\n",
            "when input is [63, 63, 2, 71, 59] the target: 56\n",
            "when input is [63, 63, 2, 71, 59, 56] the target: 70\n",
            "when input is [63, 63, 2, 71, 59, 56, 70] the target: 56\n",
            "when input is [63, 63, 2, 71, 59, 56, 70, 56] the target: 2\n",
            "when input is [70] the target: 56\n",
            "when input is [70, 56] the target: 63\n",
            "when input is [70, 56, 63] the target: 73\n",
            "when input is [70, 56, 63, 73] the target: 56\n",
            "when input is [70, 56, 63, 73, 56] the target: 70\n",
            "when input is [70, 56, 63, 73, 56, 70] the target: 1\n",
            "when input is [70, 56, 63, 73, 56, 70, 1] the target: 0\n",
            "when input is [70, 56, 63, 73, 56, 70, 1, 0] the target: 74\n",
            "when input is [2] the target: 26\n",
            "when input is [2, 26] the target: 59\n",
            "when input is [2, 26, 59] the target: 60\n",
            "when input is [2, 26, 59, 60] the target: 63\n",
            "when input is [2, 26, 59, 60, 63] the target: 72\n",
            "when input is [2, 26, 59, 60, 63, 72] the target: 55\n",
            "when input is [2, 26, 59, 60, 63, 72, 55] the target: 2\n",
            "when input is [2, 26, 59, 60, 63, 72, 55, 2] the target: 74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bigram Model Definition\n",
        "\n",
        "- The model is a very simple neural network:\n",
        "\n",
        "- Each character in the vocabulary is represented by an embedding.\n",
        "- But here, unlike common embeddings, the embedding dimension = vocabulary size (vocab_size). In other words, each token is mapped directly to a vector of logits that already indicate the probabilities of the next token.\n",
        "- That's why it's called Bigram: it only looks at one character in context to predict the next, without using a larger window."
      ],
      "metadata": {
        "id": "3TFcH2VlXxtb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ua4w5eiuXodu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}